{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "from Phytopredictor import PhytoPredictor, aggregate_phyto_data, predict, train_phytopredictor, data_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC_CODE</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>TIJD</th>\n",
       "      <th>ZS [mg/l]</th>\n",
       "      <th>ZICHT [dm]</th>\n",
       "      <th>T [oC]</th>\n",
       "      <th>SiO2 [umol/L]</th>\n",
       "      <th>SALNTT [DIMSLS]</th>\n",
       "      <th>PO4 [umol/L]</th>\n",
       "      <th>pH [DIMSLS]</th>\n",
       "      <th>...</th>\n",
       "      <th>Pde</th>\n",
       "      <th>Plo</th>\n",
       "      <th>Dpu</th>\n",
       "      <th>Rte</th>\n",
       "      <th>Fja</th>\n",
       "      <th>Hak</th>\n",
       "      <th>Mhe</th>\n",
       "      <th>Dno</th>\n",
       "      <th>Dat</th>\n",
       "      <th>interpolated_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DANTZGT</td>\n",
       "      <td>1990-01-10</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.178571</td>\n",
       "      <td>29.19</td>\n",
       "      <td>1.645161</td>\n",
       "      <td>7.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DANTZGT</td>\n",
       "      <td>1990-02-06</td>\n",
       "      <td>13:40:00</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.803571</td>\n",
       "      <td>27.37</td>\n",
       "      <td>1.177419</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['SiO2 [umol/L]', 'PO4 [umol/L]', 'pH [DIMSLS]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DANTZGT</td>\n",
       "      <td>1990-03-08</td>\n",
       "      <td>13:45:00</td>\n",
       "      <td>103.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DANTZGT</td>\n",
       "      <td>1990-04-04</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>28.79</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>8.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DANTZGT</td>\n",
       "      <td>1990-05-09</td>\n",
       "      <td>15:30:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>33.28</td>\n",
       "      <td>1.161290</td>\n",
       "      <td>8.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOC_CODE      DATUM      TIJD  ZS [mg/l]  ZICHT [dm]  T [oC]  SiO2 [umol/L]  \\\n",
       "0  DANTZGT 1990-01-10  15:00:00      135.0         2.0     4.0      20.178571   \n",
       "1  DANTZGT 1990-02-06  13:40:00      295.0         0.5     6.0      19.803571   \n",
       "2  DANTZGT 1990-03-08  13:45:00      103.0         3.0     7.3      19.428571   \n",
       "3  DANTZGT 1990-04-04  10:00:00      113.0         3.0     8.2       6.285714   \n",
       "4  DANTZGT 1990-05-09  15:30:00       20.0        11.0    17.4       1.714286   \n",
       "\n",
       "   SALNTT [DIMSLS]  PO4 [umol/L]  pH [DIMSLS]  ...  Pde  Plo  Dpu  Rte Fja  \\\n",
       "0            29.19      1.645161          7.8  ...  NaN  NaN  NaN  NaN NaN   \n",
       "1            27.37      1.177419          7.9  ...  NaN  NaN  NaN  NaN NaN   \n",
       "2            24.99      0.709677          8.0  ...  NaN  NaN  NaN  NaN NaN   \n",
       "3            28.79      0.806452          8.1  ...  NaN  NaN  NaN  NaN NaN   \n",
       "4            33.28      1.161290          8.3  ...  NaN  NaN  NaN  NaN NaN   \n",
       "\n",
       "   Hak  Mhe  Dno  Dat                               interpolated_columns  \n",
       "0  NaN  NaN  NaN  NaN                                                 []  \n",
       "1  NaN  NaN  NaN  NaN  ['SiO2 [umol/L]', 'PO4 [umol/L]', 'pH [DIMSLS]...  \n",
       "2  NaN  NaN  NaN  NaN                                                 []  \n",
       "3  NaN  NaN  NaN  NaN                                                 []  \n",
       "4  NaN  NaN  NaN  NaN                                                 []  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../../data/MERGED_DATA_180624.xlsx', sheet_name='MERGE_FINAL')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the different columns and preparing the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = list(df.columns)\n",
    "\n",
    "abio_columns = ['ZS [mg/l]', 'T [oC]', 'SiO2 [umol/L]', 'SALNTT [DIMSLS]', 'PO4 [umol/L]', 'pH [DIMSLS]', 'NO3 [umol/L]', 'NO2 [umol/L]', 'NH4 [umol/L]', 'E [/m]', 'CHLFa [ug/l]']\n",
    "phyto_columns = ['Acn', 'Aco', 'Agl', 'Ata', 'Cau', 'Ccu', 'Cda',\n",
    "       'Cdeb', 'Cden', 'Cdi', 'Cei', 'Cfu', 'Cgr', 'Cha', 'Coc', 'Cra', 'Csu',\n",
    "       'Cwa', 'Dac', 'Dat', 'Dbr', 'Dip', 'Dle', 'Dno', 'Dpu', 'Dro', 'Dsp',\n",
    "       'Edu', 'Etr', 'Ezo', 'Fja', 'Gde', 'Gfa', 'Gfl', 'Gsp', 'Hak', 'Hta',\n",
    "       'Kgl', 'Lan', 'Lun', 'Mhe', 'Mnu', 'Mpe', 'Ndi', 'Nsc', 'Nsi', 'Oau',\n",
    "       'Omo', 'Ore', 'Orh', 'Oro', 'Osi', 'Pac', 'Pan', 'Pba', 'Pbi', 'Pbr',\n",
    "       'Pcl', 'Pco', 'Pde', 'Pha', 'Plo', 'Pmi', 'Pos', 'Pse', 'Pst', 'Psu',\n",
    "       'Pte', 'Ptr', 'Ram', 'Rse', 'Rst', 'Rte', 'Stu', 'Tec', 'Tle', 'Tni',\n",
    "       'Tno', 'Tor', 'Tro']\n",
    "loc_date_columns = [\"LOC_CODE\", \"DATUM\"]\n",
    "\n",
    "ignored_columns = set(df.columns) - set(loc_date_columns + abio_columns + phyto_columns)\n",
    "\n",
    "df = df.drop(list(ignored_columns), axis=1)\n",
    "\n",
    "# splitting the phytoplankton randomly for now\n",
    "clusters = np.split(np.asarray(phyto_columns), 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating the dataset using the clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC_CODE</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>ZS [mg/l]</th>\n",
       "      <th>T [oC]</th>\n",
       "      <th>SiO2 [umol/L]</th>\n",
       "      <th>SALNTT [DIMSLS]</th>\n",
       "      <th>PO4 [umol/L]</th>\n",
       "      <th>pH [DIMSLS]</th>\n",
       "      <th>NO3 [umol/L]</th>\n",
       "      <th>NO2 [umol/L]</th>\n",
       "      <th>NH4 [umol/L]</th>\n",
       "      <th>E [/m]</th>\n",
       "      <th>CHLFa [ug/l]</th>\n",
       "      <th>group_0</th>\n",
       "      <th>group_1</th>\n",
       "      <th>group_2</th>\n",
       "      <th>group_3</th>\n",
       "      <th>group_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DANTZGT</td>\n",
       "      <td>1990-01-10</td>\n",
       "      <td>135.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.178571</td>\n",
       "      <td>29.19</td>\n",
       "      <td>1.645161</td>\n",
       "      <td>7.8</td>\n",
       "      <td>37.571429</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>14.071429</td>\n",
       "      <td>0.751180</td>\n",
       "      <td>1.3</td>\n",
       "      <td>46.713973</td>\n",
       "      <td>48.221006</td>\n",
       "      <td>44.913413</td>\n",
       "      <td>50.458967</td>\n",
       "      <td>52.410028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DANTZGT</td>\n",
       "      <td>1990-02-06</td>\n",
       "      <td>295.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.803571</td>\n",
       "      <td>27.37</td>\n",
       "      <td>1.177419</td>\n",
       "      <td>7.9</td>\n",
       "      <td>63.428571</td>\n",
       "      <td>2.892857</td>\n",
       "      <td>11.357143</td>\n",
       "      <td>11.391822</td>\n",
       "      <td>11.2</td>\n",
       "      <td>46.713973</td>\n",
       "      <td>48.221006</td>\n",
       "      <td>44.913413</td>\n",
       "      <td>50.458967</td>\n",
       "      <td>52.410028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DANTZGT</td>\n",
       "      <td>1990-03-08</td>\n",
       "      <td>103.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>19.428571</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>8.0</td>\n",
       "      <td>89.285714</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>8.642857</td>\n",
       "      <td>1.364080</td>\n",
       "      <td>21.1</td>\n",
       "      <td>46.713973</td>\n",
       "      <td>48.221006</td>\n",
       "      <td>44.913413</td>\n",
       "      <td>50.458967</td>\n",
       "      <td>52.410028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DANTZGT</td>\n",
       "      <td>1990-04-04</td>\n",
       "      <td>113.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.285714</td>\n",
       "      <td>28.79</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>8.1</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.428571</td>\n",
       "      <td>1.037580</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.713973</td>\n",
       "      <td>48.221006</td>\n",
       "      <td>44.913413</td>\n",
       "      <td>50.458967</td>\n",
       "      <td>52.410028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DANTZGT</td>\n",
       "      <td>1990-05-09</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>33.28</td>\n",
       "      <td>1.161290</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.928571</td>\n",
       "      <td>0.738760</td>\n",
       "      <td>10.2</td>\n",
       "      <td>48.111727</td>\n",
       "      <td>48.318009</td>\n",
       "      <td>43.834850</td>\n",
       "      <td>48.859339</td>\n",
       "      <td>53.866902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOC_CODE      DATUM  ZS [mg/l]  T [oC]  SiO2 [umol/L]  SALNTT [DIMSLS]  \\\n",
       "0  DANTZGT 1990-01-10      135.0     4.0      20.178571            29.19   \n",
       "1  DANTZGT 1990-02-06      295.0     6.0      19.803571            27.37   \n",
       "2  DANTZGT 1990-03-08      103.0     7.3      19.428571            24.99   \n",
       "3  DANTZGT 1990-04-04      113.0     8.2       6.285714            28.79   \n",
       "4  DANTZGT 1990-05-09       20.0    17.4       1.714286            33.28   \n",
       "\n",
       "   PO4 [umol/L]  pH [DIMSLS]  NO3 [umol/L]  NO2 [umol/L]  NH4 [umol/L]  \\\n",
       "0      1.645161          7.8     37.571429      3.714286     14.071429   \n",
       "1      1.177419          7.9     63.428571      2.892857     11.357143   \n",
       "2      0.709677          8.0     89.285714      2.071429      8.642857   \n",
       "3      0.806452          8.1     40.000000      2.000000      6.428571   \n",
       "4      1.161290          8.3      0.214286      0.142857      1.928571   \n",
       "\n",
       "      E [/m]  CHLFa [ug/l]    group_0    group_1    group_2    group_3  \\\n",
       "0   0.751180           1.3  46.713973  48.221006  44.913413  50.458967   \n",
       "1  11.391822          11.2  46.713973  48.221006  44.913413  50.458967   \n",
       "2   1.364080          21.1  46.713973  48.221006  44.913413  50.458967   \n",
       "3   1.037580          25.0  46.713973  48.221006  44.913413  50.458967   \n",
       "4   0.738760          10.2  48.111727  48.318009  43.834850  48.859339   \n",
       "\n",
       "     group_4  \n",
       "0  52.410028  \n",
       "1  52.410028  \n",
       "2  52.410028  \n",
       "3  52.410028  \n",
       "4  53.866902  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_phyto_df, group_labels = aggregate_phyto_data(df, clusters)\n",
    "\n",
    "grouped_phyto_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Dataframe for each Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DANTZGT: (598, 16)\n",
      "DREISR: (584, 16)\n",
      "GOERE6: (374, 16)\n",
      "GROOTGND: (588, 16)\n",
      "HANSWGL: (589, 16)\n",
      "HUIBGOT: (588, 16)\n",
      "LODSGT: (584, 16)\n",
      "MARSDND: (590, 16)\n",
      "NOORDWK10: (918, 16)\n",
      "NOORDWK2: (580, 16)\n",
      "NOORDWK20: (550, 16)\n",
      "NOORDWK70: (550, 16)\n",
      "ROTTMPT3: (289, 16)\n",
      "ROTTMPT50: (210, 16)\n",
      "ROTTMPT70: (210, 16)\n",
      "SCHAARVODDL: (816, 16)\n",
      "SOELKKPDOT: (584, 16)\n",
      "TERSLG10: (542, 16)\n",
      "TERSLG100: (461, 16)\n",
      "TERSLG135: (462, 16)\n",
      "TERSLG175: (373, 16)\n",
      "TERSLG235: (372, 16)\n",
      "TERSLG4: (288, 16)\n",
      "VLISSGBISSVH: (690, 16)\n",
      "WALCRN2: (373, 16)\n",
      "WALCRN20: (371, 16)\n",
      "WALCRN70: (371, 16)\n"
     ]
    }
   ],
   "source": [
    "location_groups = grouped_phyto_df.groupby(\"LOC_CODE\")\n",
    "\n",
    "location_data_dict = {}\n",
    "for name, loc_df in location_groups:\n",
    "    \n",
    "    loc_df = loc_df.drop(['DATUM', 'LOC_CODE'], axis=1)\n",
    "    \n",
    "    location_data_dict[name] = loc_df\n",
    "\n",
    "for key, value in location_data_dict.items():\n",
    "    print(f\"{key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhytoPredictor(\n",
      "  (history_encoder): LSTM(5, 5)\n",
      "  (FFNN): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=8, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aec9eef1547418c852c2e217c42ce25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# optimiser is Adam for now, but can be changed\u001b[39;00m\n\u001b[1;32m     27\u001b[0m optimiser \u001b[38;5;241m=\u001b[39m Adam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m model, training_loss_log, evaluation_loss_log, percentage_error_log \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_phytopredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mtrial_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mabio_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mgroup_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mshuffled_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mminimum_lookback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mlookback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mloss_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mcheck_interval\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Uni/2eJaarsKIProject2024/scripts/NN/Phytopredictor.py:383\u001b[0m, in \u001b[0;36mtrain_phytopredictor\u001b[0;34m(model, optimiser, data, trial_name, abio_columns, phyto_columns, shuffled_rows, random_seed, train_ratio, minimum_lookback, lookback, loss_metric, device, epochs, check_interval, no_print)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# every so often we check whether the model has improved or not (so we can save the best version)\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m check_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \n\u001b[1;32m    381\u001b[0m \n\u001b[1;32m    382\u001b[0m     \u001b[38;5;66;03m# we do a first pass of the evaluation set and calculate the current loss (as a base thingy)\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m     _, eval_loss, percentage_error \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcalc_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcalc_percentage_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;66;03m# and record the loss ofcourse\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     evaluation_loss_log\u001b[38;5;241m.\u001b[39mappend(eval_loss)\n",
      "File \u001b[0;32m~/Documents/Uni/2eJaarsKIProject2024/scripts/NN/Phytopredictor.py:228\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, data, device, loss_metric, calc_loss, calc_percentage_error)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# if we want to calculate the loss and keep track of it, we do the following\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m calc_loss:\n\u001b[0;32m--> 228\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabio_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphyto_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactual_concentrations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_metric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m     all_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m calc_percentage_error:\n",
      "File \u001b[0;32m~/Documents/Uni/2eJaarsKIProject2024/scripts/NN/Phytopredictor.py:126\u001b[0m, in \u001b[0;36mPhytoPredictor.loss\u001b[0;34m(self, input_data, expected_concentrations, metric)\u001b[0m\n\u001b[1;32m    123\u001b[0m abio_data, phyto_data \u001b[38;5;241m=\u001b[39m input_data\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Predicting phytoplankton concentrations\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m predicted_concentrations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabio_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphyto_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# calculating the loss based on the chosen metric\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Uni/2eJaarsKIProject2024/scripts/NN/Phytopredictor.py:82\u001b[0m, in \u001b[0;36mPhytoPredictor.forward\u001b[0;34m(self, abio_data, phyto_input)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mForward pass of the model to predict phytoplankton concentrations.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03mtorch.Tensor: Predicted phytoplankton concentrations tensor of shape (batch_size, output_size).\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# first we predict using the neural network to get the logits\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabio_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphyto_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# after acquiring the logits from the model, we use a ReLU activation function to hopefully get results\u001b[39;00m\n\u001b[1;32m     85\u001b[0m output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(logits)\n",
      "File \u001b[0;32m~/Documents/Uni/2eJaarsKIProject2024/scripts/NN/Phytopredictor.py:160\u001b[0m, in \u001b[0;36mPhytoPredictor._predict_logits\u001b[0;34m(self, abio_input, phyto_input)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mPredicts logits (raw output) before activation using the model's components.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mtorch.Tensor: Logits tensor before activation of shape (batch_size, output_size).\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# pretty sure we should be using hx, but we can use the others if I am wrong\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m u, (hx, cx) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphyto_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# size is [1, 2 * clusters] if bidirectional else [1, clusters]\u001b[39;00m\n\u001b[1;32m    163\u001b[0m encoded_history \u001b[38;5;241m=\u001b[39m hx\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    883\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_size_phyto = len(clusters)\n",
    "input_size_abio = len(abio_columns)\n",
    "lstm_hidden_size = input_size_phyto\n",
    "ffnn_hidden_size = max(input_size_abio - 3, 5)\n",
    "output_size = input_size_phyto\n",
    "p_drop = 0.5\n",
    "bidirectional = False\n",
    "\n",
    "trial_name = \"First Test\"\n",
    "shuffled_rows = True\n",
    "random_seed = 2\n",
    "train_ratio = 0.7\n",
    "minimum_lookback = 10\n",
    "lookback = -1\n",
    "loss_metric = \"MSE\"\n",
    "epochs = 10\n",
    "check_interval = 10\n",
    "\n",
    "# for now we just train for DANTZGT\n",
    "data = location_data_dict[\"DANTZGT\"]\n",
    "\n",
    "model = PhytoPredictor(input_size_phyto, lstm_hidden_size, input_size_abio, ffnn_hidden_size, output_size, p_drop, bidirectional)\n",
    "\n",
    "# optimiser is Adam for now, but can be changed\n",
    "optimiser = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model, training_loss_log, evaluation_loss_log, percentage_error_log = train_phytopredictor(model, \n",
    "                                                                     optimiser, \n",
    "                                                                     data, \n",
    "                                                                     trial_name, \n",
    "                                                                     abio_columns, \n",
    "                                                                     group_labels, \n",
    "                                                                     shuffled_rows, \n",
    "                                                                     random_seed, \n",
    "                                                                     train_ratio, \n",
    "                                                                     minimum_lookback, \n",
    "                                                                     lookback, \n",
    "                                                                     loss_metric,\n",
    "                                                                     device,\n",
    "                                                                     epochs,\n",
    "                                                                     check_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_loss_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_loss_log_np \u001b[38;5;241m=\u001b[39m [loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtraining_loss_log\u001b[49m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ty chatgpt for this ez function :)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmoving_average\u001b[39m(data, window_size):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_loss_log' is not defined"
     ]
    }
   ],
   "source": [
    "training_loss_log_np = [loss.detach().numpy() for loss in training_loss_log]\n",
    "\n",
    "# ty chatgpt for this ez function :)\n",
    "def moving_average(data, window_size):\n",
    "    cumsum = np.cumsum(data, dtype=float)\n",
    "    cumsum[window_size:] = cumsum[window_size:] - cumsum[:-window_size]\n",
    "    return cumsum[window_size - 1:] / window_size\n",
    "\n",
    "window_size = 100\n",
    "smoothed_training_loss = moving_average(training_loss_log_np, window_size)\n",
    "\n",
    "averaged_training_loss = [np.mean(training_loss_log_np[i:i+10]) for i in range(0, len(training_loss_log_np), 10)]\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 4))\n",
    "_ = axs[0].plot(np.arange(len(training_loss_log_np)), training_loss_log_np)\n",
    "_ = axs[0].set_xlabel('Steps')\n",
    "_ = axs[0].set_ylabel('Training Loss')\n",
    "_ = axs[1].plot(np.arange(len(smoothed_training_loss)), smoothed_training_loss)\n",
    "_ = axs[1].set_xlabel('Steps')\n",
    "_ = axs[1].set_ylabel('Smoothed Training Loss')\n",
    "_ = axs[2].plot(np.arange(len(evaluation_loss_log)) * check_interval, evaluation_loss_log)\n",
    "_ = axs[2].set_xlabel('Steps')\n",
    "_ = axs[2].set_ylabel('Validation Loss')\n",
    "_ = axs[3].plot(np.arange(len(percentage_error_log)) * check_interval, percentage_error_log)\n",
    "_ = axs[3].set_xlabel('Steps')\n",
    "_ = axs[3].set_ylabel('Percentage Error')\n",
    "\n",
    "_ = fig.tight_layout(h_pad=2, w_pad=2)\n",
    "\n",
    "print(\"Last training loss: \", training_loss_log_np[-1])\n",
    "print(\"Last evaluation loss: \", evaluation_loss_log[-1])\n",
    "print(\"Last percentage error: \", percentage_error_log[-1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimise the parameters with Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'lstm_hidden_size': [len(clusters) - 1, len(clusters), len(clusters) + 1],\n",
    "    'ffnn_hidden_size': [max(input_size_abio - 3, 5) - 1, max(input_size_abio - 3, 5)],\n",
    "    'p_drop': [0.1, 0.3],\n",
    "    'lr': [0.0001, 0.001, 0.01],\n",
    "    'lookback': [10, 50, -1]\n",
    "}\n",
    "\n",
    "# Generate all combinations of hyperparameters\n",
    "keys, values = zip(*param_grid.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "print(len(combinations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combinations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Iterate over all combinations of hyperparameters\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mcombinations\u001b[49m):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(combinations)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) combination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m     evaluation_loss \u001b[38;5;241m=\u001b[39m train_and_evaluate(params)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combinations' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "def train_and_evaluate(params):\n",
    "    # Create model and optimizer with the given hyperparameters\n",
    "    model = PhytoPredictor(input_size_phyto, params[\"lstm_hidden_size\"], input_size_abio, \n",
    "                           params[\"ffnn_hidden_size\"], output_size, params['p_drop'], \n",
    "                           False)\n",
    "    optimizer = Adam(model.parameters(), lr=params['lr'])\n",
    "    \n",
    "    # Train the model\n",
    "    model, training_loss_log, evaluation_loss_log, percentage_error_log = train_phytopredictor(\n",
    "        model, optimizer, data, trial_name, abio_columns, group_labels, shuffled_rows,\n",
    "        random_seed, 0.7, minimum_lookback, params['lookback'], \n",
    "        loss_metric, device, epochs, check_interval, no_print=True\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    evaluation_loss = evaluation_loss_log[-1]  # Assuming the last value is the evaluation loss\n",
    "    \n",
    "    return evaluation_loss\n",
    "\n",
    "# Initialize variables to store the best hyperparameters and the corresponding loss\n",
    "best_params = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "# Iterate over all combinations of hyperparameters\n",
    "for i, params in enumerate(combinations):\n",
    "    print(f\"Testing ({i}/{len(combinations)}) combination: {params}\")\n",
    "    evaluation_loss = train_and_evaluate(params)\n",
    "    \n",
    "    if evaluation_loss < best_loss:\n",
    "        best_loss = evaluation_loss\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\n\\n\\n------------GRID SEARCH DONE------------\")\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(best_params)\n",
    "print(f\"Validation Loss: {best_loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
